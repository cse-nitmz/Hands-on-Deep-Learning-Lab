{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Neural Networks with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project requires Python 3.10 or above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "assert sys.version_info >= (3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also requires Scikit-Learn ≥ 1.6.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from packaging.version import Version\n",
    "import sklearn\n",
    "\n",
    "assert Version(sklearn.__version__) >= Version(\"1.6.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %pip install -q optuna torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course we need PyTorch, specifically PyTorch ≥ 2.6.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "assert Version(torch.__version__) >= Version(\"2.6.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the default font sizes to make the figures prettier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('axes', labelsize=14, titlesize=14)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rc('xtick', labelsize=10)\n",
    "plt.rc('ytick', labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Fundamentals\n",
    "## PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 4.0, 7.0], [2.0, 3.0, 6.0]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ([[1.0, 4.0, 7.0], [2.0, 3.0, 6.0]])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 7.],\n",
       "        [2., 3., 6.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "X = torch.tensor([[1.0, 4.0, 7.0], [2.0, 3.0, 6.0]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0, 1] # X[row, column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 3.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20., 50., 80.],\n",
       "        [30., 40., 70.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 * (X + 1.0)  # item-wise addition and multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   2.7183,   54.5981, 1096.6332],\n",
       "        [   7.3891,   20.0855,  403.4288]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8333)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 4., 7., 2., 3., 6.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8333333333333335"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mean_Test = (1.0 + 4.0 + 7.0 + 2.0 + 3.0 + 6.0) / 6\n",
    "Mean_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.8333)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sum() / len(X.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.return_types.max(\n",
       " values=tensor([2., 4., 7.]),\n",
       " indices=tensor([1, 0, 0])),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max(dim=0), X.shape # 0 ---> each column value maximum, 1 ---> each row value maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[66., 56.],\n",
       "        [56., 49.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X @ X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 4., 7.],\n",
       "       [2., 3., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X.numpy() # we convert torch into numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 7.],\n",
       "        [2., 3., 6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([[1., 4., 7.], [2., 3., 6.]])) # we can also convert numpy into torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 7.],\n",
       "        [2., 3., 6.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([[1., 4., 7.], [2., 3., 6.]]), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 4., 7.],\n",
       "        [2., 3., 6.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(np.array([[1., 4., 7.], [2., 3., 6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., 88.,  7.],\n",
       "        [ 2.,  3.,  6.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a NumPy array\n",
    "X2_np = np.array([[1., 4., 7.], [2., 3., 6]])\n",
    "\n",
    "# Convert NumPy array to PyTorch tensor WITHOUT copying memory\n",
    "# Both X2_np and X2 point to the same underlying data\n",
    "X2 = torch.from_numpy(X2_np)\n",
    "\n",
    "# Modify the NumPy array\n",
    "# This change will also appear in the tensor because memory is shared\n",
    "X2_np[0, 1] = 88\n",
    "\n",
    "# Printing X2 will reflect the updated value (88)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1., -99.,   7.],\n",
       "        [  2., -99.,   6.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 1] = -99\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 7.],\n",
       "        [2., 0., 6.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply ReLU activation IN-PLACE\n",
    "# ReLU replaces all negative values with 0 and keeps positive values unchanged\n",
    "# The underscore (_) means the tensor X is modified directly (no new tensor created)\n",
    "X.relu_()\n",
    "\n",
    "# X now contains the updated values after ReLU\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch tensors really resemble NumPy arrays. In fact, they have over 200 common functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__getattr__, abs, absolute, acos, acosh, add, all, allclose, amax, amin, angle, any, arange, arccos, arccosh, arcsin, arcsinh, arctan, arctan2, arctanh, argmax, argmin, argsort, argwhere, asarray, asin, asinh, atan, atan2, atanh, atleast_1d, atleast_2d, atleast_3d, bincount, bitwise_and, bitwise_left_shift, bitwise_not, bitwise_or, bitwise_right_shift, bitwise_xor, broadcast_shapes, broadcast_to, can_cast, ceil, clip, column_stack, concat, concatenate, conj, copysign, corrcoef, cos, cosh, count_nonzero, cov, cross, cumprod, cumsum, deg2rad, diag, diagflat, diagonal, diff, divide, dot, dsplit, dstack, dtype, einsum, empty, empty_like, equal, exp, exp2, expm1, eye, finfo, fix, flip, fliplr, flipud, float_power, floor, floor_divide, fmax, fmin, fmod, frexp, from_dlpack, frombuffer, full, full_like, gcd, gradient, greater, greater_equal, heaviside, histogram, histogramdd, hsplit, hstack, hypot, i0, iinfo, imag, inner, isclose, isfinite, isin, isinf, isnan, isneginf, isposinf, isreal, kron, lcm, ldexp, less, less_equal, linspace, load, log, log10, log1p, log2, logaddexp, logaddexp2, logical_and, logical_not, logical_or, logical_xor, logspace, matmul, max, maximum, mean, median, meshgrid, min, minimum, moveaxis, multiply, nan_to_num, nanmean, nanmedian, nanquantile, nansum, negative, nextafter, nonzero, not_equal, ones, ones_like, outer, positive, pow, prod, promote_types, put, quantile, rad2deg, ravel, real, reciprocal, remainder, reshape, result_type, roll, rot90, round, row_stack, save, searchsorted, select, set_printoptions, sign, signbit, sin, sinc, sinh, sort, split, sqrt, square, squeeze, stack, std, subtract, sum, swapaxes, take, tan, tanh, tensordot, tile, trace, transpose, trapezoid, trapz, tril, tril_indices, triu, triu_indices, true_divide, trunc, typename, unique, unravel_index, vander, var, vdot, vsplit, vstack, where, zeros, zeros_like'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra code: list functions that appear both in NumPy and PyTorch\n",
    "functions = lambda mod: set(f for f in dir(mod) if callable(getattr(mod, f)))\n",
    "\", \".join(sorted(functions(torch) & functions(np)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
    "M = M.to(device)\n",
    "M.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = torch.tensor([[1., 2., 3.], [4., 5., 6.]], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14., 32.],\n",
       "        [32., 77.]], device='cuda:0')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = M @ M.T  # run some operations on the GPU\n",
    "R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.08 ms ± 47 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "570 μs ± 10.6 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "M = torch.rand((1000, 1000))  # on the CPU\n",
    "M @ M.T  # warmup\n",
    "%timeit M @ M.T\n",
    "\n",
    "M = M.to(device)\n",
    "M @ M.T  # warmup\n",
    "%timeit M @ M.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a simple function, $f(x) = x^2$.\n",
    "Calculus tells us that the derivative of this function is $f'(x)=2x$. Let's evaluate $f(5)$ and the derivative $f'(5)$ using autograd. We expect to find $f(5)=5^2=25$ and $f'(5)=2*5=10$. Let's see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25., grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "f = x ** 2\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.backward() # backpropagation\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5., requires_grad=True), tensor(25., grad_fn=<PowBackward0>))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the core idea: **move parameters in the opposite direction of the gradient to reduce loss.**\n",
    "\n",
    "---\n",
    "\n",
    "* `x` → parameter\n",
    "* `x.grad` → gradient (computed by autograd)\n",
    "* `learning_rate`\n",
    "* subtraction → moving downhill on the loss surface\n",
    "\n",
    "`torch.no_grad()` is the practical addition — it prevents PyTorch from tracking the update itself in the computation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "with torch.no_grad():\n",
    "    x -= learning_rate * x.grad  # gradient descent step \n",
    "   #5 -= 0.1 * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., requires_grad=True)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could have used this code for the gradient descent step (but using `no_grad()` is more common for this):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_detached = x.detach()\n",
    "x_detached -= learning_rate * x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., requires_grad=True)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put everything together to get our training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "tensor(10.)\n",
      "tensor(4., requires_grad=True)\n",
      "-----------------\n",
      "tensor(8.)\n",
      "tensor(3.2000, requires_grad=True)\n",
      "-----------------\n",
      "tensor(6.4000)\n",
      "tensor(2.5600, requires_grad=True)\n",
      "-----------------\n",
      "tensor(5.1200)\n",
      "tensor(2.0480, requires_grad=True)\n",
      "-----------------\n",
      "tensor(4.0960)\n",
      "tensor(1.6384, requires_grad=True)\n",
      "-----------------\n",
      "tensor(3.2768)\n",
      "tensor(1.3107, requires_grad=True)\n",
      "-----------------\n",
      "tensor(2.6214)\n",
      "tensor(1.0486, requires_grad=True)\n",
      "-----------------\n",
      "tensor(2.0972)\n",
      "tensor(0.8389, requires_grad=True)\n",
      "-----------------\n",
      "tensor(1.6777)\n",
      "tensor(0.6711, requires_grad=True)\n",
      "-----------------\n",
      "tensor(1.3422)\n",
      "tensor(0.5369, requires_grad=True)\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "x = torch.tensor(5.0, requires_grad=True)\n",
    "print(\"-----------------\")\n",
    "for iteration in range(10):\n",
    "    f = x ** 2  # forward pass\n",
    "    f.backward()  # backward pass\n",
    "    with torch.no_grad():\n",
    "        x -= learning_rate * x.grad  # gradient descent step\n",
    "    print(x.grad)\n",
    "    print(x)\n",
    "    print(\"-----------------\")\n",
    "    x.grad.zero_()  # reset the gradients, it clear accumulated gradients so each iteration uses only the current gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `x` gets pushed towards 0, since that's the value that minimizes $f(x) = x^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0185e-09, requires_grad=True)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Linear Regression\n",
    "## Linear Regression Using Tensors & Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]], shape=(20640, 8)),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894], shape=(20640,)),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 20640\\n\\n:Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n:Attribute Information:\\n    - MedInc        median income in block group\\n    - HouseAge      median house age in block group\\n    - AveRooms      average number of rooms per household\\n    - AveBedrms     average number of bedrooms per household\\n    - Population    block group population\\n    - AveOccup      average number of household members\\n    - Latitude      block group latitude\\n    - Longitude     block group longitude\\n\\n:Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. rubric:: References\\n\\n- Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n  Statistics and Probability Letters, 33:291-297, 1997.\\n'}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# convert features to dataframe\n",
    "housing_df = pd.DataFrame(housing['data'], columns=housing['feature_names'])\n",
    "\n",
    "# add target column\n",
    "housing_df['MedHouseVal'] = housing['target']\n",
    "\n",
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "X_valid = torch.FloatTensor(X_valid)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "\n",
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.8918e+00,  2.8625e+01,  5.4559e+00,  1.0996e+00,  1.4243e+03,\n",
       "           2.9589e+00,  3.5646e+01, -1.1958e+02]]),\n",
       " tensor([[1.9094e+00, 1.2641e+01, 2.5505e+00, 4.6548e-01, 1.0958e+03, 2.3615e+00,\n",
       "          2.1347e+00, 2.0010e+00]]))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = X_train.mean(dim=0, keepdims=True)\n",
    "stds = X_train.std(dim=0, keepdims=True)\n",
    "\n",
    "means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1940, -1.0778, -0.9433,  ..., -0.5729,  0.9292, -1.4221],\n",
       "        [ 0.7520, -1.8688,  0.4055,  ...,  0.2052, -0.9165,  1.0966],\n",
       "        [-0.4147,  0.0297,  0.8181,  ..., -0.2998,  1.3087, -1.6970],\n",
       "        ...,\n",
       "        [-1.2233,  0.5043, -0.5160,  ...,  0.1345, -0.7198,  1.1466],\n",
       "        [-0.9355,  1.8491, -0.1088,  ..., -0.0135,  0.5217, -0.1028],\n",
       "        [ 0.8958,  0.1879,  0.2995,  ..., -0.1782,  1.1213, -1.3071]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardization (z-score normalization)\n",
    "\n",
    "X_train = (X_train - means) / stds\n",
    "X_valid = (X_valid - means) / stds\n",
    "X_test = (X_test - means) / stds\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11610, 8]), (11610,))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch expects the targets to have one row per sample, so let's reshape the targets to be column vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = torch.FloatTensor(y_train).view(-1, 1)\n",
    "y_valid = torch.FloatTensor(y_valid).view(-1, 1)\n",
    "y_test = torch.FloatTensor(y_test).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11610, 1])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "n_features = X_train.shape[1]  # there are 8 input features\n",
    "\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3367],\n",
       "         [ 0.1288],\n",
       "         [ 0.2345],\n",
       "         [ 0.2303],\n",
       "         [-1.1229],\n",
       "         [-0.1863],\n",
       "         [ 2.2082],\n",
       "         [-0.6380]], requires_grad=True),\n",
       " tensor(0., requires_grad=True))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.randn((n_features, 1), requires_grad=True)\n",
    "b = torch.tensor(0., requires_grad=True)\n",
    "\n",
    "w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: in the next section, we will build an almost identical model using PyTorch's high-level API. Its results will be slightly different because it will use a different parameter initialization method: it will use a uniform random distribution from $-\\frac{1}{2\\sqrt 2}$ to $+\\frac{1}{2\\sqrt 2}$ to initialize both the weights and the bias term. If you want to get exactly the same result here as in the next section, you can uncomment and run the initialization code in the following cell, instead of the code in the previous cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(42)\n",
    "# n_features = X_train.shape[1]  # there are 8 input features\n",
    "# r = 2 ** -1.5  # this is equal to 1 / 2√2\n",
    "# w = torch.empty(n_features, 1).uniform_(-r, r)\n",
    "# b = torch.empty(1).uniform_(-r, r)\n",
    "# w.requires_grad_(True)\n",
    "# b.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 16.158456802368164\n",
      "Epoch 2/20, Loss: 4.879366397857666\n",
      "Epoch 3/20, Loss: 2.2552270889282227\n",
      "Epoch 4/20, Loss: 1.3307628631591797\n",
      "Epoch 5/20, Loss: 0.9680694937705994\n",
      "Epoch 6/20, Loss: 0.8142679929733276\n",
      "Epoch 7/20, Loss: 0.7417047023773193\n",
      "Epoch 8/20, Loss: 0.7020702362060547\n",
      "Epoch 9/20, Loss: 0.6765919923782349\n",
      "Epoch 10/20, Loss: 0.6577966213226318\n",
      "Epoch 11/20, Loss: 0.6426153182983398\n",
      "Epoch 12/20, Loss: 0.6297224760055542\n",
      "Epoch 13/20, Loss: 0.6184942722320557\n",
      "Epoch 14/20, Loss: 0.608596920967102\n",
      "Epoch 15/20, Loss: 0.5998217463493347\n",
      "Epoch 16/20, Loss: 0.5920187830924988\n",
      "Epoch 17/20, Loss: 0.5850691795349121\n",
      "Epoch 18/20, Loss: 0.578873336315155\n",
      "Epoch 19/20, Loss: 0.573345422744751\n",
      "Epoch 20/20, Loss: 0.5684100985527039\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.4\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    y_pred = X_train @ w + b\n",
    "    loss = ((y_pred - y_train) ** 2).mean()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        b -= learning_rate * b.grad\n",
    "        w -= learning_rate * w.grad\n",
    "        b.grad.zero_()\n",
    "        w.grad.zero_()\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = X_test[:3]  # pretend these are new instances\n",
    "with torch.no_grad():\n",
    "    y_pred = X_new @ w + b  # use the trained parameters to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8916],\n",
       "        [1.6480],\n",
       "        [2.6577]])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Using PyTorch's High-Level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(42)  # to get reproducible results\n",
    "model = nn.Linear(in_features=n_features, out_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.3117], requires_grad=True)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2703,  0.2935, -0.0828,  0.3248, -0.0775,  0.0713, -0.1721,  0.2076]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3117], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4718],\n",
       "        [ 0.1131]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bgd(model, optimizer, criterion, X_train, y_train, n_epochs):\n",
    "    for epoch in range(n_epochs):\n",
    "        y_pred = model(X_train)\n",
    "        loss = criterion(y_pred, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 4.3378496170043945\n",
      "Epoch 2/20, Loss: 0.780293345451355\n",
      "Epoch 3/20, Loss: 0.6253840327262878\n",
      "Epoch 4/20, Loss: 0.6060433387756348\n",
      "Epoch 5/20, Loss: 0.5956299304962158\n",
      "Epoch 6/20, Loss: 0.5873566269874573\n",
      "Epoch 7/20, Loss: 0.5802990198135376\n",
      "Epoch 8/20, Loss: 0.5741382241249084\n",
      "Epoch 9/20, Loss: 0.5687100887298584\n",
      "Epoch 10/20, Loss: 0.5639079213142395\n",
      "Epoch 11/20, Loss: 0.5596510767936707\n",
      "Epoch 12/20, Loss: 0.5558737516403198\n",
      "Epoch 13/20, Loss: 0.5525193810462952\n",
      "Epoch 14/20, Loss: 0.5495391488075256\n",
      "Epoch 15/20, Loss: 0.5468899011611938\n",
      "Epoch 16/20, Loss: 0.544533908367157\n",
      "Epoch 17/20, Loss: 0.5424376130104065\n",
      "Epoch 18/20, Loss: 0.5405715703964233\n",
      "Epoch 19/20, Loss: 0.5389096736907959\n",
      "Epoch 20/20, Loss: 0.5374288558959961\n"
     ]
    }
   ],
   "source": [
    "train_bgd(model, optimizer, mse, X_train, y_train, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8061],\n",
       "        [1.7116],\n",
       "        [2.6973]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]  # pretend these are new instances\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_new)  # use the trained model to make predictions\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Regression MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 40),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(40, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 5.045480251312256\n",
      "Epoch 2/20, Loss: 2.0523128509521484\n",
      "Epoch 3/20, Loss: 1.0039883852005005\n",
      "Epoch 4/20, Loss: 0.8570139408111572\n",
      "Epoch 5/20, Loss: 0.7740675210952759\n",
      "Epoch 6/20, Loss: 0.7225848436355591\n",
      "Epoch 7/20, Loss: 0.6893726587295532\n",
      "Epoch 8/20, Loss: 0.6669033765792847\n",
      "Epoch 9/20, Loss: 0.6507738828659058\n",
      "Epoch 10/20, Loss: 0.6383934617042542\n",
      "Epoch 11/20, Loss: 0.6281994581222534\n",
      "Epoch 12/20, Loss: 0.6193399429321289\n",
      "Epoch 13/20, Loss: 0.6113173365592957\n",
      "Epoch 14/20, Loss: 0.6038705706596375\n",
      "Epoch 15/20, Loss: 0.5968308448791504\n",
      "Epoch 16/20, Loss: 0.5901119112968445\n",
      "Epoch 17/20, Loss: 0.5836468935012817\n",
      "Epoch 18/20, Loss: 0.5774064064025879\n",
      "Epoch 19/20, Loss: 0.5713555216789246\n",
      "Epoch 20/20, Loss: 0.565444827079773\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "mse = nn.MSELoss()\n",
    "train_bgd(model, optimizer, mse, X_train, y_train, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Mini-Batch Gradient Descent using DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code – build the model just like earlier\n",
    "torch.manual_seed(42)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 50), nn.ReLU(),\n",
    "    nn.Linear(50, 40), nn.ReLU(),\n",
    "    nn.Linear(40, 1)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# extra code – build the optimizer and loss function, as earlier\n",
    "learning_rate = 0.02\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_loader, n_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            #print(X_batch.shape)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, Loss: {mean_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.5900\n",
      "Epoch 2/20, Loss: 0.4046\n",
      "Epoch 3/20, Loss: 0.3801\n",
      "Epoch 4/20, Loss: 0.3629\n",
      "Epoch 5/20, Loss: 0.3529\n",
      "Epoch 6/20, Loss: 0.3520\n",
      "Epoch 7/20, Loss: 0.3408\n",
      "Epoch 8/20, Loss: 0.3426\n",
      "Epoch 9/20, Loss: 0.3407\n",
      "Epoch 10/20, Loss: 0.3378\n",
      "Epoch 11/20, Loss: 0.3304\n",
      "Epoch 12/20, Loss: 0.3267\n",
      "Epoch 13/20, Loss: 0.3244\n",
      "Epoch 14/20, Loss: 0.3221\n",
      "Epoch 15/20, Loss: 0.3188\n",
      "Epoch 16/20, Loss: 0.3148\n",
      "Epoch 17/20, Loss: 0.3122\n",
      "Epoch 18/20, Loss: 0.3111\n",
      "Epoch 19/20, Loss: 0.3086\n",
      "Epoch 20/20, Loss: 0.3087\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, mse, train_loader, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, metric_fn, aggregate_fn=torch.mean):\n",
    "    model.eval()  # switch model to evaluation mode (disables dropout, uses batchnorm running stats)\n",
    "    metrics = []\n",
    "    with torch.no_grad():  # disable gradient tracking to save memory and computation\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # move data to CPU/GPU\n",
    "            y_pred = model(X_batch)  # forward pass\n",
    "            metric = metric_fn(y_pred, y_batch)  # compute batch metric (e.g., MSE/RMSE)\n",
    "            #print(metric)\n",
    "            metrics.append(metric)  # store metric for aggregation\n",
    "    return aggregate_fn(torch.stack(metrics))  # combine all batch metrics into final score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4160, device='cuda:0')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset = TensorDataset(X_valid, y_valid)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32)\n",
    "valid_mse = evaluate(model, valid_loader, mse)\n",
    "valid_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5687, device='cuda:0')"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rmse(y_pred, y_true):\n",
    "    return ((y_pred - y_true) ** 2).mean().sqrt()\n",
    "\n",
    "evaluate(model, valid_loader, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6450, device='cuda:0')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_mse.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6450, device='cuda:0')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, valid_loader, mse,\n",
    "         aggregate_fn=lambda metrics: torch.sqrt(torch.mean(metrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "def evaluate_tm(model, data_loader, metric):\n",
    "    model.eval()\n",
    "    metric.reset()  # reset the metric at the beginning\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            metric.update(y_pred, y_batch)  # update it at each iteration\n",
    "    return metric.compute()  # compute the final result at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6450, device='cuda:0')"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "evaluate_tm(model, valid_loader, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, train loss: 0.7826, train metric: 0.8847, valid metric: 0.6690\n",
      "Epoch 2/20, train loss: 0.4362, train metric: 0.6605, valid metric: 0.6099\n",
      "Epoch 3/20, train loss: 0.3930, train metric: 0.6269, valid metric: 0.6145\n",
      "Epoch 4/20, train loss: 0.3759, train metric: 0.6132, valid metric: 0.5963\n",
      "Epoch 5/20, train loss: 0.3649, train metric: 0.6040, valid metric: 0.5911\n",
      "Epoch 6/20, train loss: 0.3598, train metric: 0.5999, valid metric: 0.5965\n",
      "Epoch 7/20, train loss: 0.3530, train metric: 0.5941, valid metric: 0.6062\n",
      "Epoch 8/20, train loss: 0.3495, train metric: 0.5911, valid metric: 0.6043\n",
      "Epoch 9/20, train loss: 0.3454, train metric: 0.5877, valid metric: 0.5723\n",
      "Epoch 10/20, train loss: 0.3416, train metric: 0.5845, valid metric: 0.6037\n",
      "Epoch 11/20, train loss: 0.3400, train metric: 0.5830, valid metric: 0.5880\n",
      "Epoch 12/20, train loss: 0.3362, train metric: 0.5799, valid metric: 0.5738\n",
      "Epoch 13/20, train loss: 0.3352, train metric: 0.5788, valid metric: 0.5881\n",
      "Epoch 14/20, train loss: 0.3310, train metric: 0.5754, valid metric: 0.5893\n",
      "Epoch 15/20, train loss: 0.3292, train metric: 0.5738, valid metric: 0.5581\n",
      "Epoch 16/20, train loss: 0.3273, train metric: 0.5721, valid metric: 0.5753\n",
      "Epoch 17/20, train loss: 0.3264, train metric: 0.5714, valid metric: 0.5780\n",
      "Epoch 18/20, train loss: 0.3238, train metric: 0.5691, valid metric: 0.5733\n",
      "Epoch 19/20, train loss: 0.3207, train metric: 0.5663, valid metric: 0.5563\n",
      "Epoch 20/20, train loss: 0.3191, train metric: 0.5649, valid metric: 0.5611\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train2(model, optimizer, criterion, metric, train_loader, valid_loader,\n",
    "               n_epochs):\n",
    "    history = {\"train_losses\": [], \"train_metrics\": [], \"valid_metrics\": []}\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0.\n",
    "        metric.reset()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            model.train()\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            metric.update(y_pred, y_batch)\n",
    "        mean_loss = total_loss / len(train_loader)\n",
    "        history[\"train_losses\"].append(mean_loss)\n",
    "        history[\"train_metrics\"].append(metric.compute().item())\n",
    "        history[\"valid_metrics\"].append(\n",
    "            evaluate_tm(model, valid_loader, metric).item())\n",
    "        print(f\"Epoch {epoch + 1}/{n_epochs}, \"\n",
    "              f\"train loss: {history['train_losses'][-1]:.4f}, \"\n",
    "              f\"train metric: {history['train_metrics'][-1]:.4f}, \"\n",
    "              f\"valid metric: {history['valid_metrics'][-1]:.4f}\")\n",
    "    return history\n",
    "\n",
    "torch.manual_seed(42)\n",
    "learning_rate = 0.01\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(n_features, 50), nn.ReLU(),\n",
    "    nn.Linear(50, 40), nn.ReLU(),\n",
    "    nn.Linear(40, 30), nn.ReLU(),\n",
    "    nn.Linear(30, 1)\n",
    ")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0)\n",
    "mse = nn.MSELoss()\n",
    "rmse = torchmetrics.MeanSquaredError(squared=False).to(device)\n",
    "history = train2(model, optimizer, mse, rmse, train_loader, valid_loader,\n",
    "                 n_epochs)\n",
    "\n",
    "# Since we compute the training metric\n",
    "plt.plot(np.arange(n_epochs) + 0.5, history[\"train_metrics\"], \".--\",\n",
    "         label=\"Training\")\n",
    "plt.plot(np.arange(n_epochs) + 1.0, history[\"valid_metrics\"], \".-\",\n",
    "         label=\"Validation\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.grid()\n",
    "plt.title(\"Learning curves\")\n",
    "plt.axis([0.5, 20, 0.4, 1.0])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading a PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"my_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = torch.load(\"my_model.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.eval()\n",
    "pred_model = evaluate_tm(model, valid_loader, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5957, device='cuda:0')"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### **PyTorch Assignment — Real-World Classification Using MLP**\n",
    "\n",
    "**Objective:**\n",
    "Train and evaluate a Multi-Layer Perceptron (MLP) on a real-world classification dataset using proper preprocessing, batching, and evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "### **Dataset (choose one)**\n",
    "\n",
    "Students must use a real tabular dataset:\n",
    "\n",
    "* Breast Cancer Wisconsin (medical diagnosis)\n",
    "* Wine dataset (quality classification)\n",
    "\n",
    "---\n",
    "\n",
    "### **Task 1 — Data Preparation**\n",
    "\n",
    "1. Load the dataset.\n",
    "2. Convert features and labels into PyTorch tensors.\n",
    "3. Normalize input features using training statistics only.\n",
    "4. Split into train, validation, and test sets.\n",
    "5. Create `DataLoader` with mini-batching.\n",
    "\n",
    "---\n",
    "\n",
    "### **Task 2 — Build an MLP Classifier**\n",
    "\n",
    "1. Design an MLP with at least two hidden layers.\n",
    "2. Use ReLU activation.\n",
    "3. Output layer must match number of classes.\n",
    "4. Use **CrossEntropyLoss** (no softmax in the model).\n",
    "\n",
    "Students must explain why logits are used instead of probabilities.\n",
    "\n",
    "---\n",
    "\n",
    "### **Task 3 — Training Loop**\n",
    "\n",
    "1. Implement mini-batch gradient descent.\n",
    "2. Track training loss and accuracy per epoch.\n",
    "3. Reset gradients correctly.\n",
    "4. Plot loss and accuracy curves.\n",
    "\n",
    "---\n",
    "\n",
    "### **Task 4 — Evaluation**\n",
    "\n",
    "1. Switch to evaluation mode before validation/testing.\n",
    "2. Compute test accuracy.\n",
    "3. Generate a confusion matrix.\n",
    "4. Identify one class the model struggles with and explain why.\n",
    "\n",
    "---\n",
    "\n",
    "### **Task 5 — Experimentation**\n",
    "\n",
    "Change one factor and analyze impact:\n",
    "\n",
    "* learning rate\n",
    "* hidden layer size\n",
    "* number of layers\n",
    "* optimizer (SGD vs Adam)\n",
    "\n",
    "---\n",
    "\n",
    "### **Bonus Insight Task**\n",
    "\n",
    "1. Train the model **without normalization** and compare results.\n",
    "2. Train without resetting gradients and explain behavior.\n",
    "3. Add dropout and observe generalization.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
